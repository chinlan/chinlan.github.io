---
layout: post
title: "AWS ECS"
description: "Deploy api backend app (Rails) and frontend app (Next.js + React.js + TypeScript) to AWS ECS"
categories: [devops]
tags: []
redirect_from:
  - /2020/07/27/
---
There are several ways to deploy your apps to AWS ECS:

## Using `ecs-cli`
(Assume that VPC, subnets, security group, keypair and ECS cluster configuration are all created beforehand using `aws-cli` or aws console. And the docker images of frontend and backend containers are already build, tagged and pushed to AWS ECR.)

- Adding `ecs-params.yml` file
~~~ yaml
version: 1
task_definition:
  services:
    backend:
      cpu_shares: 200
      mem_limit: 954
      mem_reservation: 512
    frontend:
      cpu_shares: 100
      mem_limit: 954
      mem_reservation: 512
      memswap_limit: 954
~~~

- Adding `docker-compose.production.yml` file if staging environment needs some different setting from development environment
~~~ yaml
version: "3" # AWS ecs-cli compose only support primary version, 2.3 is not supported

services:
  frontend:
    restart: always
    working_dir: /frontend
    ports:
      - 4000:4000
    image: xxxxxxxxxx.dkr.ecr.ap-northeast-1.amazonaws.com/frontend_deploy
    entrypoint: /frontend-entrypoint.sh

  web:
    restart: always
    image: xxxxxxxxxx.dkr.ecr.ap-northeast-1.amazonaws.com/backend_deploy
    working_dir: /app
    ports:
      - 3000:3000
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"
    env_file:
      - variables-deploy.env
    entrypoint: /docker-entrypoint.sh

networks:
  default:
    external:
      name: myapp-network
~~~

- Create the cluster:
`ecs-cli up --keypair MyKeyPair --capability-iam --instance-type t2.small --cluster MyAppCluster --security-group sg-xxxxxxxxxx --vpc vpc-xxxxxxxxxx --subnets subnet-xxxxxxxx, subnet-xxxxxxxxxxx  --force`

- If need to destroy the cluster:
`ecs-cli down --force --cluster MyAppCluster`

- After the cluster is created:
`ecs-cli compose --project-name MyAppCluster --file docker-compose.production.yml up --cluster-config default`

This way, 2 containers are all in the same task_definition, just like in the development environment running `docker-compose up`.

But I want to separate 2 containers to 2 services in the cluster, so it can be scaled and managed better in the future.

Also this way I will need to manually build image after revising the codes.
`docker image build -t backend_deploy -f Dockerfile-deploy --no-cache .`

## Using Terraform and circleCI
On both backend and frontend side, edit `.circleci` folder:
- `.circleci/config.yml`
~~~ yaml
---
version: 2.1

orbs:
  aws-ecr: circleci/aws-ecr@6.10.0
  aws-ecs: circleci/aws-ecs@1.2.0

jobs:
  build:
    working_directory: ~/xxxInc/my-app-frontend
    parallelism: 1
    environment:
      CIRCLE_ARTIFACTS: /tmp/circleci-artifacts
      CIRCLE_TEST_REPORTS: /tmp/circleci-test-results
      RAILS_ENV: test
      RACK_ENV: test
    docker:
      - image: circleci/node:10.21-browsers
    steps:
      - run: mkdir -p $CIRCLE_ARTIFACTS $CIRCLE_TEST_REPORTS
      - checkout
      - restore_cache:
          keys:
            - node-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "package-lock.json" }}
            - node-cache-v1-{{ arch }}-{{ .Branch }}
            - node-cache-v1
      - run: npm i
      - save_cache:
          key: node-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          when: always
          command: npx eslint main
      - run:
          when: always
          command: npx eslint manager
      - store_test_results:
          path: /tmp/circleci-test-results
      - store_artifacts:
          path: /tmp/circleci-artifacts
      - store_artifacts:
          path: /tmp/circleci-test-results

workflows:
  build-and-deploy:
    jobs:
      - build
      - aws-ecr/build-and-push-image:
          name: build-staging-image
          account-url: AWS_ECR_ACCOUNT_URL
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          path:
          dockerfile: .circleci/staging/Dockerfile-frontend-deploy
          repo: "job-docker_frontend_deploy"
          tag: "latest,${CIRCLE_SHA1}"
          requires:
            - build
          filters:
            branches:
              only: staging
      - aws-ecs/deploy-service-update:
          name: deploy-to-staging
          family: "ninninjob-frontend-staging"
          cluster-name: "ninninjob-staging"
          skip-task-definition-registration: true
          force-new-deployment: true
          requires:
            - build-staging-image
          filters:
            branches:
              only: staging
      - aws-ecr/build-and-push-image:
          name: build-production-image
          account-url: AWS_ECR_ACCOUNT_URL
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          dockerfile: .circleci/production/Dockerfile-frontend-deploy
          repo: "job-docker_frontend_deploy"
          tag: "latest,${CIRCLE_SHA1}"
          requires:
            - build
          filters:
            branches:
              only: production
      - aws-ecs/deploy-service-update:
          name: deploy-to-production
          family: "ninninjob-frontend-production"
          cluster-name: "ninninjob-production"
          skip-task-definition-registration: true
          force-new-deployment: true
          requires:
            - build-production-image
          filters:
            branches:
              only: production
~~~

~~~yaml
---
version: 2.1

orbs:
  aws-ecr: circleci/aws-ecr@6.10.0
  aws-ecs: circleci/aws-ecs@1.2.0

jobs:
  build:
    working_directory: ~/xxxInc/my-app
    parallelism: 1
    environment:
      CIRCLE_ARTIFACTS: /tmp/circleci-artifacts
      CIRCLE_TEST_REPORTS: /tmp/circleci-test-results
      RAILS_ENV: test
      RACK_ENV: test
    docker:
      - image: dockerkun/rbj_node_browsers_circle:2.6.6
        environment:
          REDIS_URL: localhost
          DB_HOST: 127.0.0.1
          DB_USERNAME: root
          DB_PASSWORD: circleci
          DB_NAME_TEST: circleci
          TZ: /usr/share/zoneinfo/Asia/Tokyo
      - image: circleci/mysql:8.0.18-ram
        command: mysqld --default-authentication-plugin=mysql_native_password
        environment:
          MYSQL_ROOT_PASSWORD: circleci
          MYSQL_DATABASE: circleci
          MYSQL_ROOT_HOST: '%'
          TZ: /usr/share/zoneinfo/Asia/Tokyo
      - image: dockerkun/elasticsearch-icu-kuromoji:7.1.0
        auth:
          username: $DOCKERHUB_USERNAME
          password: $DOCKERHUB_PASSWORD
        environment:
          discovery.type: single-node
          discovery.zen.minimum_master_nodes: 1
          cluster.name: elastic-ci
          xpack.security.enabled: false
          network.host: 0.0.0.0
          http.port: 9200
          ES_JAVA_OPTS: -Xms512m -Xmx512m
          TZ: /usr/share/zoneinfo/Asia/Tokyo
      - image: redis:4
        environment:
          TZ: /usr/share/zoneinfo/Asia/Tokyo
      - image: mongo:4.2
        environment:
          TZ: /usr/share/zoneinfo/Asia/Tokyo
    steps:
      - run: mkdir -p $CIRCLE_ARTIFACTS $CIRCLE_TEST_REPORTS
      - run: sudo apt-get update
      - run: sudo apt-get install build-essential
      - checkout
      - run:
          working_directory: ~/NinNinInc/jobb
          command: mv config/secrets.ci.yml config/secrets.yml
      - run: cp .env.example .env
      - restore_cache:
          keys:
            - gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
            - gem-cache-v1-{{ arch }}-{{ .Branch }}
            - gem-cache-v1
      - run: bundle check --path vendor/bundle || bundle install --jobs=4 --retry=3 --path vendor/bundle
      - save_cache:
          key: gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
          paths:
            - vendor/bundle
      - run: bundle exec rake db:create db:schema:load --trace
      - run:
          when: always
          command: bundle exec rspec --color --require spec_helper --format progress spec
      - run:
          when: always
          command: bundle exec rails_best_practices .
      - run:
          when: always
          command: bundle exec brakeman -z --rails5
      - run:
          when: always
          command: bundle exec reek
      - run:
          when: always
          command: bundle exec rubocop
      - store_test_results:
          path: /tmp/circleci-test-results
      - store_artifacts:
          path: /tmp/circleci-artifacts
      - store_artifacts:
          path: /tmp/circleci-test-results

workflows:
  build-and-deploy:
    jobs:
      - build
      - aws-ecr/build-and-push-image:
          name: build-staging-image
          account-url: AWS_ECR_ACCOUNT_URL
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          dockerfile: .circleci/staging/Dockerfile-deploy --build-arg RAILS_ENV=staging --build-arg RAILS_MASTER_KEY=${RAILS_MASTER_KEY} --build-arg AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} --build-arg AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
          repo: "job-docker_web_deploy"
          tag: "latest,${CIRCLE_SHA1}"
          requires:
            - build
          filters:
            branches:
              only: staging
      - aws-ecs/deploy-service-update:
          name: deploy-to-staging
          family: "ninninjob-web-staging"
          cluster-name: "ninninjob-staging"
          skip-task-definition-registration: true
          force-new-deployment: true
          requires:
            - build-staging-image
          filters:
            branches:
              only: staging
      - aws-ecr/build-and-push-image:
          name: build-production-image
          account-url: AWS_ECR_ACCOUNT_URL
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          dockerfile: .circleci/production/Dockerfile-deploy --build-arg RAILS_ENV=production --build-arg RAILS_MASTER_KEY=${RAILS_MASTER_KEY} --build-arg AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} --build-arg AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
          repo: "job-docker_web_deploy"
          tag: "latest,${CIRCLE_SHA1}"
          requires:
            - build
          filters:
            branches:
              only: production
      - aws-ecs/deploy-service-update:
          name: deploy-to-production
          family: "ninninjob-web-production"
          cluster-name: "ninninjob-production"
          skip-task-definition-registration: true
          force-new-deployment: true
          requires:
            - build-production-image
          filters:
            branches:
              only: production
~~~

.circleci/staging/Dockerfile-deploy
~~~
FROM dockerkun/ruby_docker_jemalloc:2.6.6

RUN apt-get update && \
    apt-get install -y build-essential libmagickwand-dev \
    libxslt-dev libxml2-dev curl mysql-client cron vim unzip \
    --no-install-recommends && \
    curl -sL https://deb.nodesource.com/setup_8.x | bash - && \
    apt-get update && apt-get install nodejs && rm -rf /var/lib/apt/lists/* && \
    wget -N http://chromedriver.storage.googleapis.com/2.45/chromedriver_linux64.zip -P ~/ && \
    unzip ~/chromedriver_linux64.zip -d ~/ && \
    rm ~/chromedriver_linux64.zip && \
    chown root:root ~/chromedriver && \
    chmod 755 ~/chromedriver && \
    mv ~/chromedriver /usr/bin/chromedriver && \
    sh -c 'wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -' && \
    sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list' && \
    apt-get update && apt-get install -y google-chrome-stable

ADD .circleci/shared/mysql-client.cnf /etc/my.cnf

COPY . /app
WORKDIR /app

ADD ./Gemfile /app/Gemfile
ADD ./Gemfile.lock /app/Gemfile.lock
RUN gem install bundler && bundle install --jobs 20 --retry 5

RUN apt-get remove -y build-essential dpkg-dev && apt-get clean
RUN npm install elasticdump@6.0.2 -g

ENV LANG C.UTF-8

ARG ASSET_HOST=https://s3-ap-northeast-1.amazonaws.com/asset-ninninjob-jp
ARG RAILS_ENV
ARG RAILS_MASTER_KEY
ARG AWS_ACCESS_KEY_ID
ARG AWS_SECRET_ACCESS_KEY
RUN export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
RUN export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
RUN bundle exec rake RAILS_MASTER_KEY=${RAILS_MASTER_KEY} ASSET_HOST=${ASSET_HOST} RAILS_ENV=${RAILS_ENV} assets:precompile

ADD .circleci/staging/docker-entrypoint-deploy.sh /
RUN chmod +x /docker-entrypoint-deploy.sh
ENTRYPOINT ["/docker-entrypoint-deploy.sh"]
~~~

.circleci/staging/docker-entrypoint.sh
~~~sh
#!/bin/sh
set -ex

if [ ! -d /app/tmp/pids ]; then
  # Control will enter here if $DIRECTORY doesn't exist.
  mkdir -p /app/tmp/pids
fi

if [ ! -d /app/log ]; then
  mkdir -p /app/log
  if [ "$RAILS_ENV" == "staging" ]; then
    touch /app/log/staging-batch.log
    touch /app/lob/staging.log
  fi
fi

if [ -f /app/tmp/pids/server.pid ]; then
  rm /app/tmp/pids/server.pid
fi

echo "Waiting for MySQL to start..."
while ! mysqladmin ping -h"$DB_HOST" --silent; do
    sleep 1
done

bundle check || bundle install --jobs=4 --retry=3

echo "Running migrations..."
# Adding skip_on_db_migrate env variable to avoid annotate_model when starting container
RAILS_ENV="$RAILS_ENV" bundle exec rake db:exists && skip_on_db_migrate=1 bundle exec rails db:migrate || bundle exec rails db:setup

bundle exec sidekiq -C config/sidekiq.yml

bundle exec rails server -b 0.0.0.0
~~~


Remember to add the environment variables at circleCI project setting panel.

So the image update is handled by circleCI, the task definition, service, and cluster settings will be handled by terraform.

[Terraform notes](http://chinlan.github.io/blog/2020/07/24/terraform-notes/)





